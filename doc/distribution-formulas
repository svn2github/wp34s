
Normal distribution continued fraction:

The normal CDF now is more precise, but full machine precision is not
achieved. Especially in the tails (x >= 2) this could be done easily
with a simple continued fraction expansion. Unoptimized pseudo-code:

   n := 4 + 100 div (x-1)  ; see below
   s := 1/n
   for c := n-1 downto 1 do
       s := c / (s + x)
   s := s + x
   cdf := pdf(x) / s

I tried to determine a rule for the number of terms n, depending on x
and the desired accuracy (d digits). As far as I can tell on a system
working with usual binary double precision numbers (15-16 valid decimals)
this value can be estimated for d = 8...16 digits quite exactly by

   k >= 17 + d * (d-5) / 2   (the example uses k = 100 for d ~= 16)
   n >= 4 + int(k / (x-1))

This should return the value for s with d valid digits and an error
near 0,2 ULP. With 39 internal digits on the 34s the desired 16-digit
result can be evaluated without effort, since the required pdf and its
exp(-0,5*x^2) can be evaluated with sufficient precision. All this is
calculated in virtually no time.


----------------------------------------------------------------------


So the two initial guesses are somewhat off. There are various simple
ways to fix this for the normal quantile:

    * Determine a high-quality estimate by using a known approximation,
    such as the good old Hastings method (absolute error < 0,00045). Or,
    even better, the Bailey method (cf. Applied Statistics vol. 30 no. 3,
    1981), or an improved version I worked out some time ago. ;-) After
    this, a few Newton iterations will provide the exact quantile. Or,
    even better, two or three Newton-Halley steps, which is trivially
    simple here, giving about 2-3 times the number of correct digits
    with each step. Of course also the solver can be used instead.

    * If the solver is used two quite good initial guesses can be
    evaluated this way:

          0,5 >= p >= 0,15         0,15 >= p > 0
          -----------------------------------------------
          a = 3 * (0,5 - p)        a = sqrt(-2*ln(p) - e)
          b = a * 5/6              b = a - 1/4

      The exact result is in this interval. The two guesses differ only
      by 20% resp. by merely 0,25 so that the solver will find the result
      fast with only a few iterations.

Addendum: I just tried the solver in a WP34s user program with the two
initial guesses mentioned above, solving for the root of the equation
ln 1 + (cdf(x)-p)/p to avoid problems in the far tails, using the ln1+x
function. The results are returned immediately and the values I checked
show about 15 valid digits (out of the 16 used for all calculations).


----------------------------------------------------------------------


The mentioned formulas for the two initial guesses are very simple. But
they approximate the exact value with a relative error less than 20%
resp. an absolut error less than 0,25. With a little more effort we can
easily provide two better guesses which can nail down the true value
with an absolute error in the order of 10^-5 to 10^-8 (!) in the far
tails (p =< 10^-10). This is possible because here the quantile can be
evaluated by a series - the farther out in the tail, the less terms are
required, especially with a little tweaking of the "exact" series. ;-)
So it comes down to the question how much effort (and memory) can be
spent for two even better initial guesses which would require, say,
only 1/2 or 1/3 the number of iterations.

Here's a quick and dirty improvement for the far tail. It's a slight
modification of the original formula, now providing two guesses that
are only 0,09 or even merely 0,025 apart:

    0,15 >= p > 0
    -----------------------
    a = sqrt(-2*ln(p) - e)
    b = a - 1/4
    if a >= 4,5 then a = a - 1/a ; b = a - 1/11

or, even better, but on a smaller interval:

    if a >= 9 then a = a - a^-(3/4) ; b = a - 1/40

On the other hand, in the very center (i. e. p close to 0,5 resp. z close
to zero) using the solver will cause problems because there are multiple
z-values that will return the same 16-digit CDF. I would suggest the
following solution:

Near p = 0,5 the quantile can easily be calculated directly (!) by a
simple series:

     u  =  sqrt(2*Pi) * (p - 0,5)
                 1          7         127         4369         243649
     z  =  u +  -- u^3  +  -- u^5  +  --- u^7  +  ---- u^9  +  ------ u^11  +  ...
                3!         5!          7!          9!           11!

The nominators of the coefficients are integer series A002067.

For 0,495...0,505 (or |u| =< 0,0125) an exact 16-digit results requires
only four terms, i.e. up to u^7. With one more term (u^9) the result is
exact for p = 0,486...514 (or |u| =< 0,035).

This leads to the following algorithm (assuming p =< 0,5):

    if p > 0,15 then
       u = sqrt(2*Pi) * (p - 0,5)
       a = u + (u^3)/6 + (u^5)*7/120 + (u^7)*127/5040
       if p > 0,495
         then return a and quit   ; a already is exact
         else
              b = a * 1,006
              return solverresult(a, b)
       end if
    else     ; p =< 0,15
       a = sqrt(-2 * ln(p) - e)
       b = a - 1/4
       if a >= 9 then   ; far tail
          a = a - a^-(3/4)
          b = a - 1/40
       end if
       return solverresult (a, b)
    end if

In other words: for p > 0,15 determine a very good first guess. If p is
close enough to 0,5 this guess already is exact, so simply return it as
the final result. Otherwise provide a second guess slightly higher and
let the solver do the rest. Which is done very quickly since the error
is less than 0,6%. In the tails determine two reasonably good guesses,
and in the far tails two even better ones that reduce the remaining
error by a factor of 10.





And another one:


And here it is - I designed a rational approximation, hand crafted to meet our needs. ;-) It has the following properties:

    It works for probabilities down to 1E-500 or |z| up to 48.
    It requires only four numeric constants with just two or three significant digits.
    No special care has been taken of the center (z very close to zero) since here the exact quantile can be evaluated easily.
    It returns an estimate for |z| which is slightly high (in absolute terms). The absolute error is greater than 0,0001 and less than 0,0036. So this estimate and a second guess 0,0037 lower define an interval that definitely includes the exact quantile. 

So the normal quantile can now be evaluated this way:

if p > 0,5
   then
      signflag = false
      q = 1 - p
   else
      signflag = true
      q = p
   endif
if q >= 0,495
   then  ; use series and determine exact result
      t = (0,5 - q)^2 * 2 * Pi     
      z = (127/5040*t + 7/120)*t + 1/6)*t + 1) * sqrt(t)
   else  ; use solver with two close guesses a and b
      t = sqrt(-2 * ln(q))
      a = t - (0,373*t + 2,37)/((0,068*t + 1,1)*t + 1)
      b = a - 0,0037
      z = solver(a, b)
   endif
if signflag then z = -z
return z








Student's T estimate:

The second important distribution we should take a closer look at now is
Student's t-distribution. I have been experimenting a while with several
approaches, and I finally got a result that I think is fine as a first
estimate. Use at your own risk, expect any error you can imagine, but
try this:

    * For df = 1 or 2 degrees of freedom the quantile can be determined
    directly.
      This also is the case for n = 4, it only requires a bit care at
      very low t (close to zero) or p close to 0,5.

    * For other degrees of freedom, i.e. df >= 3, the following method
    provides a nice first estimate. As usual, p is assumed to be less
    than 0,5 and t > 0.

         if -ln(p) < 1,7 * df then
             x = guess_normal(p)
             u = (x^3 + x) / 4 / df
             v = (x^5 / 12 + x^3 / 4) / df^2
             t = x + u + v
         else
             u = p * df * sqrt(Pi / (df/2 - 1/4))
             t = sqrt(df) / u^(1/df)
         end if

Here guess_normal is the well-known first estimate of the normal quantile
(with the slight modification 1/u^2 instead of 0,2/u, as mentioned
earlier). According to my results this estimate for t differs from the
exact value by something like typically +/- 1...2%, in some cases a
bit more.

This single estimate now can be used for a Newton-iteration - the first
derivative simply is the Student PDF, so we get

                   tCDF(t) - p
   t_new  =  t  -  -----------
                     tPDF(t)

If two guesses are required (e.g. for the 34s solver) we can simply use
1.1*t and 0.9*t (or something similar).




Chi Squared estimate:


The following approximation is based on the well-known 1931 Wilson and
Hilferty transformation (cf Abramovitz and Stegun, 26.4.17). While this
method gives nice results in the center, it fails for p close to 0 or 1.
So two additional approximations are used. One of them was adapted from
Applied Statistics algorithm AS91 by Best and Roberts (1975), including
some additional later improvements from 1991. The Fortran code is
available at http://lib.stat.cmu.edu/apstat/91

AS91 evaluates a first initial guess for the Chi^2 quantile which then
is improved in a Taylor series iteration. For our purpose only an
initial guess is required, since the rest is done by the 34s solver or a
dedicated Newton-style algorithm. Since AS91 requires two logs and a
gamma function for p close to 1, in our case a homebrew approximation
with similar precision is used instead, requiring only one log. The
whole thing was finally streamlined and slightly tweaked for best
results with our initial guess for the normal quantile which is used
here once again. All in all, with probability p and n degrees of
freedom, the result looks like this:

function guess_chi(p, n)

nhalf = n/2
If n > 15 then limit = 0.85 else limit = 1

If p < exp(-limit*n) then     ' modified B+R approx. for p close to 0
  lng = lngamma(nhalf)
  ch = 2 * (p * nhalf)^(1/nhalf) * exp(lng/nhalf)
else
  x = 0.97 * guess_normal(p) ' Wilson + Hilferty for the center
  u = 0.2214 / n             ' works better than 2/9 = 0.2222
  ch = n * (x * sqrt(u) - u + 1) ^ 3
  If ch > 6*n + 16 then      ' my own adjustment for p close to 1
     ch = ch * (1 + ln1plusx(-p) / (150*n))
end if

guess_chi = ch

end function


According to my results, for all positive integer n the error is within
-9%...+7% of the true value. I tested p from 1E-307 up to 1 - 1E-16 and
n from 1 to 1000 and higher.

Once again, the first guess relies on the same normal estimate procedure
as it is used in the Normal and Student case. However, please note that
guess_normal(p) here has to accept any 0 < p < 1 and not just up to 0,5
as in the Normal and Student case with their symmetric PDF. Since p is
the left hand integral (from 0 to Chi^2) the sign convention is as
usual: p < 0,5 has to return a negative guess_normal, and p > 0,5 a
positive one. As it turned out, the results improve if the normal
estimate is slightly decreased - which is the reason for the 0,97.

For n = 1 guess_chi may return zero for p very close to zero (near
1E-200). This is perfectly okay since the estimate here actually agrees
with the true value in 400 (!) decimal places and the full precision
result (pi/2 * p^2) simply underflows as well. So, if the guess is zero
we already have the true value and no further iteration is required
(which would cause numeric problems anyway).

This implementation returns a valid guess even for large n. On a
15-digit system I got good results even for n > 1000. In this case the
term exp(-0.85*n) will soon underflow to zero, which numerically is no
problem. If an underflow has to be avoided for other reasons, the test
can be changed to ln(p) < -limit*n.

The estimate still requires one gamma function, or here a lngamma() to
increase the useable range of n. If n <= 410 is sufficient (the 34s
Gamma function works up to 205) the estimate for small p can be written
as  ch = 2 * (p * nhalf * gamma(nhalf))^(1/nhalf). If calling the
regular Gamma or lnGamma routine is too slow there may be a simple, yet
effective alternative Gamma function that only has to cover integers and
half-integers, similar to the short routine for the Chi^2 PDF below.

I tested this initial estimate as a first guess for a Newton
approximation and obtained 15 valid digits usually within 4 - 7
iterations, here and there a few more. In this case the Chi^2 PDF is
required, which again requires gamma(n/2). This means, we could evaluate
gamma(n/2) once at the beginning of the algorithm and then use it first
for the estimate and then for the PDF required for the Newton iteration.
Maybe even a third time for the evaluation of the Chi^2 CDF.

Another option is an optimized routine for the Chi^2 PDF, which may be
written like this:

function chi_pdf(x, n)

xhalf = x / 2
nhalf = n / 2
k = nhalf

If nhalf = int(nhalf) then r = 0.5 else r = 1 / sqrt(2 * pi * x)

while k > 1 do
  k = k - 1
  r = r * xhalf / k
  end

chi_pdf = r * exp(-xhalf)

end function

The while-loop evaluates the quotient (x/2)^(n/2)/gamma(n/2)/x while
minimizing the danger of overflow. Multiplication with exp(-n/2) finally
gives the Chi^2 pdf. It should also run faster than a straightforward
approach that calls an external gamma routine.

Using a Newton iteration, a 16-digit result usually is found with just a
few iterations. However, there were cases where the method tried to
adjust the first estimate by more than the actual error. Which in turn
required numerous iterations before the value was back near the true
result. I have not yet found out what happens in these cases, but there
is an easy fix: since the error of the estimate is at most 8 or 9%, the
delta added to the current estimate cannot exceed this value. It turned
out that the problem primarily occurs at large n where the potential
error is even less, so that a maximum correction of 3 or 4% works even
better and minimizes the number of iterations. The modified Newton
algorithm now basically looks like this:

function chi_quantile(p, n)

x = guess_chi(p,n)

if x > 0 then   ' for x = 0 (underflow) the result already is exact
 maxdelta = 0.04 * x
 repeat
   delta = (chi_cdf(x, n) - p) / chi_pdf(x, n)
   if abs(delta) > maxdelta then delta = maxdelta * sign(delta)
   x = x - delta
 until abs(delta/x) < 1E-16
end if

chi_quantile = x

end function

If you want to try the 34s solver, the two estimates may be plus and
minus 10% of the chi_guess result. However, I think a Newton approach
will converge substantially faster.



Fisher's F quantile estimate:

cf Abramovitz and Stegun, end of chapter 26, p. 961 in 1964 ed.

n1, n2 > 1  For n1=1 or n2=1 use 2 instead.


function guess_fisher(n1, n2, pp)

  r1 = 1 / (n1 - 1)
  r2 = 1 / (n2 - 1)
  h =  2 / (r1 + r2)
  x = -guess_normal(pp)
  k = (x*x - 3) / 6
  w = x * sqrt(h + k) / h - (r1 - r2) * (k + 5/6 - 2/3/h)

  guess_fisher = exp(2*w)

end function







Binomial quantile:

For the record: here is a complete binomial quantile function. It
returns a fractional value that is a linear interpolation between the
two adjacent integers that define the interval [x, x+1] in which the cdf
would have the value pp if the function was not discrete but continuous.

The main point here is that this algorithm requires just one single call
of the binomial cdf and also just one call of the pdf. The rest happens
in a loop with just a few additions and multiplications. Since the first
estimate usually is quite close to the true value only a few iterations
are required. Even if the estimate is off by 10 or 20 or even more, I
assume 20 of these loops will be executed faster than 2 or 3 loops with
a ibeta() or binomial_cdf() call inside.

I haven't tested this very thoroughly, in fact this is exactly the VBA
code that I wrote just a few minutes ago. <8)


Function binquantile(n, p, pp)

q = 1 - p

If pp >= 1 - p ^ n Then

  x = n - (1 - pp) / (p ^ n)   ' direct solution for p close to 1

Else

  If pp <= q ^ n Then

     x = pp / (q ^ n) - 1      ' direct solution for p close to 0

  Else

     z = guess_normal(pp)      ' estimate and iteration otherwise
     x = Int((z + (z * z - 1) / 6) * Sqr(n * p * (1 - p)) + n * p)

     If x < 0 Then x = 0       ' x is bounded by [0, n-1]
     If x > n - 1 Then x = n - 1

     cdf = bincdf(x, n, p)
     pdf = binpdf(x, n, p)
     poverq = p / q

     If cdf > pp Then
        Do
          dy = pdf
          cdf = cdf - dy
          pdf = pdf * x / poverq / (n - x + 1)
          x = x - 1
        Loop Until cdf <= pp
     Else
        Do
          x = x + 1
          pdf = pdf / x * poverq * (n - x + 1)
          dy = pdf
          cdf = cdf + dy
        Loop Until cdf >= pp
     End If

     x = x + (pp - cdf) / dy   ' final linear interpolation

  End If

End If

binquantile = x

End Function


The basic idea is simple:

- if pp =< cdf(0) return a linear estimate between 0 and -1.
If you prefer integer results, simply return -1

- if pp >= cdf(n-1) return a linear estimate between n-1 and n.
If you prefer integer results, simply return n-1

- otherwise evaluate an estimate x and check if it is too large or too
small. Then decrement resp. increment x and adjust the cdf accordingly.
This is easy since the new pdf can be calculated from the previous one.
Test again until the cdf drops below resp. exceeds pp. If you prefer
integer results, omit the final linear interpolation.
